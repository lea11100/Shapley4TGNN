{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config.config import CONFIG\n",
    "CONFIG = CONFIG(\"MOOC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DyGLib.models.GraphMixer import GraphMixer\n",
    "from DyGLib.models.TGAT import TGAT\n",
    "from DyGLib.models.TCL import TCL\n",
    "from DyGLib.models.CAWN import CAWN\n",
    "from DyGLib.models.DyGFormer import DyGFormer\n",
    "from DyGLib.models.MemoryModel import MemoryModel, compute_src_dst_node_time_shifts\n",
    "\n",
    "from DyGLib.models.modules import TGNN, NeuralNetworkSrcDst, BatchSubgraphs\n",
    "from DyGLib.utils.DataLoader import get_link_prediction_data\n",
    "from DyGLib.utils.utils import get_neighbor_sampler, NegativeEdgeSampler\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = CONFIG.model.trained_model_path\n",
    "edge_feat_path = CONFIG.data.folder + CONFIG.data.edge_feat_file\n",
    "node_feat_path = CONFIG.data.folder + CONFIG.data.node_feat_file\n",
    "index_path = CONFIG.data.folder + CONFIG.data.index_file\n",
    "feature_names_path = CONFIG.data.folder + CONFIG.data.feature_names_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for training, validation and testing\n",
    "node_raw_features, edge_raw_features, full_data, train_data, val_data, test_data = \\\n",
    "    get_link_prediction_data(val_ratio=0.1, test_ratio=0.1, node_dim=CONFIG.model.node_dim)\n",
    "\n",
    "# initialize validation and test neighbor sampler to retrieve temporal graph\n",
    "full_neighbor_sampler = get_neighbor_sampler(data=full_data, edge_features=edge_raw_features, sample_neighbor_strategy=CONFIG.model.sample_neighbor_strategy,\n",
    "                                                time_scaling_factor=CONFIG.model.time_scaling_factor, seed=1)\n",
    "train_neighbor_sampler = get_neighbor_sampler(data=train_data, edge_features=edge_raw_features, sample_neighbor_strategy=CONFIG.model.sample_neighbor_strategy,\n",
    "                                                time_scaling_factor=CONFIG.model.time_scaling_factor, seed=1)\n",
    "\n",
    "# create model\n",
    "if CONFIG.model.model_name == 'TGAT':\n",
    "    dynamic_backbone = TGAT(num_nodes=node_raw_features.shape[0], node_dim=node_raw_features.shape[1], edge_dim=edge_raw_features.shape[1],\n",
    "                            time_feat_dim=CONFIG.model.time_feat_dim, num_layers=CONFIG.model.num_layers, num_heads=CONFIG.model.num_heads, dropout=CONFIG.model.dropout, device=CONFIG.model.device)\n",
    "elif CONFIG.model.model_name in ['JODIE', 'DyRep', 'TGN']:\n",
    "    # four floats that represent the mean and standard deviation of source and destination node time shifts in the training data, which is used for JODIE\n",
    "    src_node_mean_time_shift, src_node_std_time_shift, dst_node_mean_time_shift_dst, dst_node_std_time_shift = \\\n",
    "        compute_src_dst_node_time_shifts(train_data.src_node_ids, train_data.dst_node_ids, train_data.node_interact_times)\n",
    "    dynamic_backbone = MemoryModel(num_nodes=node_raw_features.shape[0], node_dim=node_raw_features.shape[1], edge_dim=edge_raw_features.shape[1],\n",
    "                                    time_feat_dim=CONFIG.model.time_feat_dim, model_name=CONFIG.model.model_name, num_layers=CONFIG.model.num_layers, num_heads=CONFIG.model.num_heads,\n",
    "                                    dropout=CONFIG.model.dropout, src_node_mean_time_shift=src_node_mean_time_shift, src_node_std_time_shift=src_node_std_time_shift,\n",
    "                                    dst_node_mean_time_shift_dst=dst_node_mean_time_shift_dst, dst_node_std_time_shift=dst_node_std_time_shift, device=CONFIG.model.device)\n",
    "elif CONFIG.model.model_name == 'CAWN':\n",
    "    dynamic_backbone = CAWN(num_nodes=node_raw_features.shape[0], node_dim=node_raw_features.shape[1], edge_dim=edge_raw_features.shape[1],\n",
    "                            time_feat_dim=CONFIG.model.time_feat_dim, position_feat_dim=CONFIG.model.position_feat_dim, walk_length=CONFIG.model.walk_length,\n",
    "                            num_walk_heads=CONFIG.model.num_walk_heads, dropout=CONFIG.model.dropout, device=CONFIG.model.device)\n",
    "elif CONFIG.model.model_name == 'TCL':\n",
    "    dynamic_backbone = TCL(num_nodes=node_raw_features.shape[0], node_dim=node_raw_features.shape[1], edge_dim=edge_raw_features.shape[1],\n",
    "                            time_feat_dim=CONFIG.model.time_feat_dim, num_layers=CONFIG.model.num_layers, num_heads=CONFIG.model.num_heads,\n",
    "                            num_depths=CONFIG.model.num_neighbors + 1, dropout=CONFIG.model.dropout, device=CONFIG.model.device)\n",
    "elif CONFIG.model.model_name == 'GraphMixer':\n",
    "    dynamic_backbone = GraphMixer(num_nodes=node_raw_features.shape[0], node_dim=node_raw_features.shape[1], edge_dim=edge_raw_features.shape[1],\n",
    "                            time_feat_dim=CONFIG.model.time_feat_dim, num_tokens=CONFIG.model.num_neighbors, num_layers=CONFIG.model.num_layers, dropout=CONFIG.model.dropout, device=CONFIG.model.device)\n",
    "elif CONFIG.model.model_name == 'DyGFormer':\n",
    "    dynamic_backbone = DyGFormer(num_nodes=node_raw_features.shape[0], node_dim=node_raw_features.shape[1], edge_dim=edge_raw_features.shape[1],\n",
    "                                    time_feat_dim=CONFIG.model.time_feat_dim, channel_embedding_dim=CONFIG.model.channel_embedding_dim, patch_size=CONFIG.model.patch_size,\n",
    "                                    num_layers=CONFIG.model.num_layers, num_heads=CONFIG.model.num_heads, dropout=CONFIG.model.dropout,\n",
    "                                    max_input_sequence_length=CONFIG.model.max_input_sequence_length, device=CONFIG.model.device)\n",
    "else:\n",
    "    raise ValueError(f\"Wrong value for model_name {CONFIG.model.model_name}!\")\n",
    "\n",
    "regressor = NeuralNetworkSrcDst(input_dim=node_raw_features.shape[1], num_layers=CONFIG.model.num_reg_layers, hidden_dim=CONFIG.model.hidden_reg_layers_dim)\n",
    "model = TGNN(dynamic_backbone, regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True))\n",
    "model.to(CONFIG.model.device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_by_id(link_index):\n",
    "    src, dst, time_stamp, edge_id, true_value = full_data.src_node_ids[link_index], full_data.dst_node_ids[link_index], full_data.node_interact_times[link_index], full_data.edge_ids[link_index], 1 # type: ignore\n",
    "    return src, dst, time_stamp, edge_id, true_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2025)\n",
    "\n",
    "sampled_edge_ids = random.sample((np.where((~np.isnan(full_data.labels)) & (~np.isin(full_data.edge_ids, train_data.edge_ids)))[0]).tolist(), num_samples)\n",
    "\n",
    "edge_info_array = np.array([list(get_edge_by_id(i)) for i in sampled_edge_ids])\n",
    "edge_info = pd.DataFrame(edge_info_array, columns=[\"Src\", \"Dst\", \"Time\", \"Edge\", \"Target\"])\n",
    "\n",
    "edges = edge_info[\"Edge\"].to_numpy(dtype=int)\n",
    "\n",
    "edge_info[\"InTrain\"] = np.isin(edges, train_data.edge_ids)\n",
    "edge_info = edge_info.sort_values(by=\"InTrain\").reset_index(drop=True)\n",
    "edge_info = edge_info[edge_info.InTrain == False]\n",
    "\n",
    "srcs = edge_info[\"Src\"].to_numpy(dtype=int)\n",
    "dsts = edge_info[\"Dst\"].to_numpy(dtype=int)\n",
    "timestamps = edge_info[\"Time\"].to_numpy(dtype=\"float32\")\n",
    "targets = edge_info[\"Target\"].to_numpy(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "subgraphs_src = full_neighbor_sampler.get_multi_hop_neighbors(CONFIG.model.num_layers, srcs, timestamps, num_neighbors = CONFIG.model.num_neighbors)\n",
    "subgraphs_dst = full_neighbor_sampler.get_multi_hop_neighbors(CONFIG.model.num_layers, dsts, timestamps, num_neighbors = CONFIG.model.num_neighbors)\n",
    "edge_feat_src = full_neighbor_sampler.get_edge_features_for_multi_hop(subgraphs_src[1])\n",
    "edge_feat_dst = full_neighbor_sampler.get_edge_features_for_multi_hop(subgraphs_dst[1])\n",
    "\n",
    "subgraphs_src = BatchSubgraphs(*subgraphs_src, edge_feat_src)\n",
    "subgraphs_src.to(CONFIG.model.device)\n",
    "subgraphs_dst = BatchSubgraphs(*subgraphs_dst, edge_feat_dst)\n",
    "subgraphs_dst.to(CONFIG.model.device)\n",
    "\n",
    "predicts = model(src_node_ids=srcs,\n",
    "                dst_node_ids=dsts,\n",
    "                node_interact_times=timestamps,\n",
    "                src_subgraphs = subgraphs_src,\n",
    "                dst_subgraphs = subgraphs_dst,\n",
    "                time_gap=CONFIG.model.time_gap,\n",
    "                edges_are_positive=True).squeeze(dim=-1).sigmoid()\n",
    "\n",
    "edge_info[\"Prediction\"] = predicts.detach().cpu().numpy()\n",
    "edge_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley Value Approximations Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from Config.colors import PRIMARYCOLOR, PALLETTE, PALLETTE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from Explainers.Shapley4TGNN.Explainer import ShapleyExplainerEvents\n",
    "from Explainers.Shapley4TGNN.Explainer import ShapleyExplainerFeatures\n",
    "\n",
    "explainerEdge = ShapleyExplainerEvents(model, full_neighbor_sampler, full_data, edge_raw_features)\n",
    "explainerFeatMonteCarlo = ShapleyExplainerFeatures(model, full_neighbor_sampler, full_data, edge_raw_features, None, shapley_alg=\"MonteCarlo\", top_k=4)\n",
    "explainerFeatPermutation = ShapleyExplainerFeatures(model, full_neighbor_sampler, full_data, edge_raw_features, None, shapley_alg=\"Permutation\", top_k=4)\n",
    "\n",
    "explainerEdge.initialize()\n",
    "explainerFeatMonteCarlo.initialize()\n",
    "explainerFeatPermutation.initialize()\n",
    "\n",
    "dists12 = []\n",
    "dists13 = []\n",
    "dists23 = []\n",
    "\n",
    "timings_shap = []\n",
    "\n",
    "for src, dst, timestamp in tqdm(zip(srcs, dsts, timestamps)):   \n",
    "    shap1 = explainerEdge.explain_instance(src,dst,timestamp, silent=True)   \n",
    "    shap1_df = pd.DataFrame(np.concat((shap1[1].data, shap1[1].values)).T, columns=[\"EdgeID\", \"Value1\"])\n",
    "    shap1_df[\"EdgeID\"] = shap1_df[\"EdgeID\"].astype(\"int\")\n",
    "\n",
    "    start = time.time_ns()\n",
    "    shap2, _, _, _ = explainerFeatMonteCarlo.explain_instance(src,dst,timestamp, silent=True)\n",
    "    end = time.time_ns()\n",
    "    timings_shap.append([end-start, \"Monte Carlo\"])\n",
    "    shap2_df = pd.DataFrame(np.array(shap2)[:,[0,-1]], columns=[\"EdgeID\", \"Value2\"])\n",
    "    shap2_df[\"Value2\"] = shap2_df[\"Value2\"].astype(\"float\")\n",
    "    shap2_df[\"EdgeID\"] = shap2_df[\"EdgeID\"].astype(\"int\")\n",
    "    shap2_df = shap2_df.groupby(\"EdgeID\").sum().reset_index()\n",
    "\n",
    "    start = time.time_ns()\n",
    "    shap3, _, _, _ = explainerFeatPermutation.explain_instance(src,dst,timestamp, silent=True)\n",
    "    end = time.time_ns()\n",
    "    timings_shap.append([end-start, \"Permutation\"])\n",
    "    shap3_df = pd.DataFrame(np.array(shap3)[:,[0,-1]], columns=[\"EdgeID\", \"Value3\"])\n",
    "    shap3_df[\"Value3\"] = shap3_df[\"Value3\"].astype(\"float\")\n",
    "    shap3_df[\"EdgeID\"] = shap3_df[\"EdgeID\"].astype(\"int\")\n",
    "    shap3_df = shap3_df.groupby(\"EdgeID\").sum().reset_index()\n",
    "\n",
    "    df = pd.merge(shap1_df, shap2_df, on=\"EdgeID\")\n",
    "    df = pd.merge(df, shap3_df, on=\"EdgeID\")\n",
    "    dists12.extend(df[\"Value1\"]-df[\"Value2\"])\n",
    "    dists13.extend(df[\"Value1\"]-df[\"Value3\"])\n",
    "    dists23.extend(df[\"Value2\"]-df[\"Value3\"])\n",
    "\n",
    "\n",
    "df_dist12 = pd.DataFrame(dists12, columns=[\"Distance\"])\n",
    "df_dist12[\"Comparison\"] = \"Edge vs. Feat. (Monte Carlo)\"\n",
    "\n",
    "df_dist13 = pd.DataFrame(dists13, columns=[\"Distance\"])\n",
    "df_dist13[\"Comparison\"] = \"Edge vs. Feat. (Permutation)\"\n",
    "\n",
    "df_dist23 = pd.DataFrame(dists13, columns=[\"Distance\"])\n",
    "df_dist23[\"Comparison\"] = \"Feat. (Monte Carlo) vs. Feat. (Permutation)\"\n",
    "\n",
    "df = pd.concat([df_dist12, df_dist13, df_dist23])\n",
    "df_timings_shap = pd.DataFrame(timings_shap, columns=[\"Timing\", \"Method\"])\n",
    "df_timings_shap[\"Timing\"] = df_timings_shap[\"Timing\"]/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplt = sns.boxplot(df, x = \"Comparison\", y=\"Distance\", color=PRIMARYCOLOR)\n",
    "plt.xticks(rotation=20, horizontalalignment='right')\n",
    "plt.xlabel(\"\")\n",
    "plt.savefig(\"Documents/Images/MOOC/Distances_approx_method.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplt = sns.boxplot(df_timings_shap, x  = \"Method\", y=\"Timing\", color=PRIMARYCOLOR)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Time (in ms)\")\n",
    "plt.savefig(\"Documents/Images/MOOC/Timings_approx_method.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
